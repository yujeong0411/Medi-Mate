import os
import json
import faiss
import numpy as np
from datetime import datetime
from typing import List, Dict
from openai import OpenAI
from dotenv import load_dotenv
from kfda_data_handler import get_data_handler, search_medical_data
from embedder import UpstageEmbedder
from common_parser import create_embedding_content

# Responses APIê°€ ìƒˆë¡œ ë‚˜ì™”ì§€ë§Œ, ì•ˆì •ì„±ì„ ìœ„í•´ Chat Completions API ì‚¬ìš©

load_dotenv()

class MedicalRAGSystem:
    """ì˜êµ¬ ì €ì¥ ê°€ëŠ¥í•œ FAISS ê¸°ë°˜ RAG ì‹œìŠ¤í…œ"""

    def __init__(self, data_dir="./data"):
        # ê²½ë¡œ ì„¤ì •
        self.data_dir = data_dir
        self.index_path = os.path.join(data_dir, "medical_docs.index")
        self.documents_path = os.path.join(data_dir, "documents.json")

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(data_dir, exist_ok=True)

        # OPENAI ì„¤ì •
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        # ì„ë² ë”© ëª¨ë¸
        self.embedder = UpstageEmbedder(model_name="solar-embedding-1-large-passage")

        # ì‹ì•½ì²˜ ë°ì´í„° T
        self.data_handler = get_data_handler()

        # FAISS ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„°
        self.index = None
        self.documents = []

        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_system()

    def _initialize_system(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”: ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±"""
        if self._load_existing_index():
            print("ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
        else:
            print("ë²¡í„° DBê°€ ì—†ìŠµë‹ˆë‹¤. ë³„ë„ êµ¬ì¶• ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
            # ë¹ˆ ì¸ë±ìŠ¤ë¡œ ì‹œì‘
            self.index = None
            self.documents = []

    def _load_existing_index(self) -> bool:
        """ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ"""
        try:
            if os.path.exists(self.index_path) and os.path.exists(self.documents_path):
                # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
                self.index = faiss.read_index(self.index_path)
                
                # ë©”íƒ€ë°ì´í„° ë¡œë“œ
                with open(self.documents_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.documents = data['documents']
                
                return True
                
        except Exception as e:
            print(f"ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")

        return False

    def _rebuild_index(self, documents: List[Dict]):
        """ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
        
        # ì„ë² ë”© ìƒì„±
        contents = [doc["content"] for doc in documents]
        embeddings = self.embedder.encode(contents)
        
        # FAISS ì¸ë±ìŠ¤ ìƒì„±
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatIP(dimension)
        
        # L2 ì •ê·œí™” í›„ ì¶”ê°€
        faiss.normalize_L2(embeddings)
        self.index.add(embeddings.astype('float32'))
        
        
        self.documents = documents
        
        # ë””ìŠ¤í¬ì— ì €ì¥
        self._save_to_disk()

    def _save_to_disk(self):
        """ì¸ë±ìŠ¤ë¥¼ ë””ìŠ¤í¬ì— ì €ì¥"""
        try:
            # FAISS ì¸ë±ìŠ¤ ì €ì¥
            faiss.write_index(self.index, self.index_path)
            
            data = {
                'documents': self.documents,
                'last_updated': datetime.now().isoformat()
            }
            with open(self.documents_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„ ì €ì¥
            with open(self.last_update_path, 'w') as f:
                f.write(datetime.now().isoformat())
            
        except Exception as e:
            print(f"ë””ìŠ¤í¬ ì €ì¥ ì‹¤íŒ¨: {e}")
            
    def search_documents(self, query: str, top_k: int = 3) -> List[Dict]:
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ - ë²¡í„° ê²€ìƒ‰"""
        if self.index is None:
            return []
        
        # 1. ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        query_embedding = self.embedder.encode([query])
        faiss.normalize_L2(query_embedding)
        
        # 2. FAISSì—ì„œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° + ê²€ìƒ‰
        scores, indices = self.index.search(query_embedding.astype('float32'), top_k)
        
        # 3. ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²°ê³¼ ë°˜í™˜
        results = []
        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
            if idx != -1 and idx < len(self.documents):  # ìœ íš¨í•œ ì¸ë±ìŠ¤
                doc = self.documents[idx]
                results.append({
                    **doc,  # ì§ì ‘ í•„ë“œ ë°©ì‹ - ì „ì²´ ë¬¸ì„œ ê·¸ëŒ€ë¡œ
                    "similarity_score": float(score),
                })
        
        return results

    def search_with_api(self, query: str) -> List[Dict]:
        """ì‹¤ì‹œê°„ ì‹ì•½ì²˜ API ê²€ìƒ‰ (ìƒˆë¡œìš´ ì•½ë¬¼ ì§ˆë¬¸ ì‹œ)"""
        try:
            api_results = search_medical_data(query)
            
            if not api_results:
                return []
            
            # API ê²°ê³¼ë¥¼ RAG í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            formatted_results = []
            for doc in api_results:
                # content í•„ë“œ ì¶”ê°€í•˜ì§€ ë§ê³  ë°”ë¡œ ìœ ì‚¬ë„ ê³„ì‚°
                doc_text = create_embedding_content(doc)

                # ì‹¤ì œ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = self.calculate_similarity(query, doc_text)
                
                formatted_results.append({
                    **doc,  # API ê²°ê³¼ë„ ì§ì ‘ í•„ë“œ ë°©ì‹
                    "similarity_score": similarity,  
                })
            
            return formatted_results
            
        except Exception as e:
            print(f"ì‹¤ì‹œê°„ API ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
        
    def calculate_similarity(self, query:str, document: str) -> float:
        """ì¿¼ë¦¬ê³¼ ë¬¸ì„œ ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            # ì¿¼ë¦¬ ë¬¸ì„œë¥¼ ê°ê° ì„ë² ë”©
            query_embedding = self.embedder.encode([query])
            doc_embedding = self.embedder.encode([document])

            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            query_norm = query_embedding / np.linalg.norm(query_embedding)
            doc_norm = doc_embedding / np.linalg.norm(doc_embedding)
            similarity = np.dot(query_norm, doc_norm.T)[0][0]

            return float(similarity)
        
        except Exception as e:
            print(f"ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.0
        
    def rank_by_similarity(self, query:str, documents: List[Dict]) -> List[Dict]:
        """ì‹¤ì‹œê°„ ë²¡í„° ìœ ì‚¬ë„ë¡œ ë¬¸ì„œ ì¬ìˆœìœ„í™”"""
        if not documents:
            return []
        
        scored_documents = []

        for doc in documents:
            # content í•„ë“œ ëŒ€ì‹  ë™ì  ìƒì„±
            doc_text = create_embedding_content(doc)
            similarity_score = self.calculate_similarity(query, doc_text)
            
            doc_copy = doc.copy()
            doc_copy["similarity_score"] = similarity_score
            scored_documents.append(doc_copy)
        
        # ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        scored_documents.sort(key=lambda x:x["similarity_score"], reverse=True)

        # ìˆœìœ„ ì¶”ê°€
        for i, doc in enumerate(scored_documents):
            doc["rank"] = i + 1

        return scored_documents
            
    def generate_response_with_sources(self, query: str, search_results: List[Dict]) -> Dict:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ OpenAIë¡œ ì‘ë‹µ ìƒì„±"""

        if not search_results:
            return {
                "response": "ê´€ë ¨ëœ ì˜ë£Œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "sources": [],
                "search_results": [],
                "model_used": "no_results"
            }
        
        # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
        context = self._create_minimal_context(search_results, query)

        # ì‚¬ìš©ììš© ì™„ì „í•œ ì†ŒìŠ¤ ì •ë³´ ìƒì„±
        sources_info = []
        for i, result in enumerate(search_results, 1):
            sources_info.append({
                "rank": i,
                "source": result.get("source", ""),
                "drug_name": result.get("drug_name", ""),
                "category": result.get("category", ""),
                "company_name": result.get("company_name", ""),
                "similarity": result.get("similarity_score", 0.0),
                "url": result.get("url", "")  # ì‚¬ìš©ì í´ë¦­ìš© URL
            })
        
        # OpenAI í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = """ë‹¹ì‹ ì€ ì•½í•™ ì •ë³´ ì œê³µ ì „ë¬¸ AIì•¼. ë‹¤ìŒ ê·œì¹™ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•´ì„œ ë‹µë³€í•´ì¤˜.:

ğŸ” **ê²€ìƒ‰ ê¸°ë°˜ ì‘ë‹µ ì›ì¹™**:
1. ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì—ë§Œ ê¸°ë°˜í•˜ì—¬ ë‹µë³€í•´ì¤˜.
2. ì¶”ì²œ ì•½ë¬¼ì´ ì—¬ëŸ¬ê°€ì§€ë¼ë©´ ê°€ì¥ í”í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì•½ë¬¼(ì•½êµ­ì—ì„œ êµ¬í•  ìˆ˜ ìˆëŠ” ì•½ë¬¼)ë¡œ 2ê°€ì§€ ì •ë„ ì¶”ì²œí•´ì¤˜.
3. ì•½ë¬¼ì˜ ì „ì²´ ì •ë³´ë¥¼ ì›í•˜ëŠ”ê±°ë©´ 1ë²ˆ ì‘ë‹µêµ¬ì¡°ë¡œ ë‹µë³€í•˜ê³ , íŠ¹ì • ì§ˆë¬¸ì´ ìˆë‹¤ë©´(ë³µìš©ë²•, ìµœëŒ€ìš©ëŸ‰ ë“±) ê·¸ê²ƒë§Œ ëŒ€ë‹µí•´ì¤˜.
4. ëª¨ë“  ë‹µë³€ ëì— "âš ï¸ ì´ ì •ë³´ëŠ” ì˜ë£Œì§„ ìƒë‹´ì„ ëŒ€ì²´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤." í¬í•¨í•´ì¤˜.
5. ì§„ë‹¨ì´ë‚˜ ì²˜ë°©ì€ ì ˆëŒ€ í•˜ì§€ë§ˆ.

# 1ë²ˆ ì‘ë‹µ êµ¬ì¡°:
ğŸ’Š ì•½ë¬¼ëª… : \n
1. ì•½ì˜ íš¨ëŠ¥ (ëª…í™•í•˜ê²Œ ë‹¨ì–´ë¡œ ë‚˜ì—´í•´ì¤˜. ì˜ˆ: ì½§ë¬¼, ì¬ì±„ê¸°, ë°œì—´)\n
2. ìƒì„¸ ì •ë³´
    - ìš©ë²•: (ì•½ë¬¼ ì‚¬ìš©ë²•ì„ ì•Œì•„ë³´ê¸° ì‰½ê²Œ ì ì–´ì¤˜.)
    - ìµœëŒ€ ìš©ëŸ‰
    - ë³µìš© ì‹œ ì£¼ì˜ì‚¬í•­
    - ë³‘ìš©ë²• (ë³‘ìš© ì‹œ ì£¼ì˜ì‚¬í•­ì´ ìˆë‹¤ë©´)
    - ë¶€ì‘ìš©
    - ë³´ê´€ë²•

# ê·¸ì™¸ ì‘ë‹µ êµ¬ì¡°:
ì˜ˆ: 1.íƒ€ì´ë ˆë†€ ì–¼ë§ˆë‚˜ ë¨¹ì„ ìˆ˜ ìˆì–´? -> ğŸ’¡ ìµœëŒ€ìš©ëŸ‰ :
2. íƒ€ì´ë ˆë†€ ë¨¹ì„ ë•Œ ì£¼ì˜í• ê±° ìˆì–´? -> ğŸ’¡ ë³µìš©ì‹œ ì£¼ì˜ì‚¬í•­ : 
"""

        user_prompt = f"""ì§ˆë¬¸: {query}

ì°¸ê³  ë¬¸ì„œ:
{context}

ìœ„ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì•ˆì „í•œ ë‹µë³€ì„ ì œê³µí•´ì¤˜."""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=300,
                temperature=0.1,  # ì¼ê´€ëœ ì‘ë‹µì„ ìœ„í•´ ë‚®ì€ temperature
            )
            
            ai_response = response.choices[0].message.content
            
            return {
                "response": ai_response,
                "sources": sources_info,
                "search_results": search_results,
                "model_used": "gpt-4o-mini"
            }
            
        except Exception as e:
            print(f"OpenAI API ì˜¤ë¥˜: {e}")
            return {
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ëœ ì •ë³´ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
                "sources": sources_info,
                "search_results": search_results,
                "error": str(e)
            }
        
    def _create_minimal_context(self, search_results: List[Dict], query: str) -> str:
        """AIìš© ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        
        parts = []
        
        for i, result in enumerate(search_results, 1):
            drug_name = result.get('drug_name', '')
            
            # ëª¨ë“  ì£¼ìš” ì •ë³´ë¥¼ í¬í•¨ (ì´ë¯¸ ì••ì¶•ë˜ì–´ ìˆìŒ)
            info_parts = [f"ì•½ë¬¼: {drug_name}"]
            
            for field in ['íš¨ê³¼', 'ë³µìš©ë²•', 'ì£¼ì˜ì‚¬í•­', 'ìƒí˜¸ì‘ìš©', 'ë¶€ì‘ìš©', 'ë³´ê´€ë²•']:
                value = result.get(field, '')
                if value:
                    info_parts.append(f"{field}: {value}")
            
            parts.append(f"[{i}] " + " / ".join(info_parts))
        
        return "\n".join(parts)
    
    def process_query(self, query: str) -> Dict:
        """ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        # 1. ë²¡í„° ì¸ë±ìŠ¤ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰
        vector_results = self.search_documents(query, top_k=3)

        # 2. # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•˜ë©´ ì‹¤ì‹œê°„ api ê²€ìƒ‰ 
        low_similarity = any(result['similarity_score'] < 0.5 for result in vector_results)
        if len(vector_results) < 2 or low_similarity:
            api_results = self.search_with_api(query)

            if api_results:
                api_results = self.rank_by_similarity(query, api_results)
        else:
            api_results = []

        # 3. ê²°ê³¼ ì¡°í•© (ë²¡í„° ê²€ìƒ‰ ìš°ì„ , api ê²€ìƒ‰ ë³´ì™„)
        all_results = vector_results +  api_results
        all_results.sort(key=lambda x:x['similarity_score'], reverse=True)

        # 4. ìƒìœ„ 3ê°œë§Œ ì„ íƒ
        if len(all_results) > 3:
            all_results = all_results[:3]

        # 5. OpenAIë¡œ ì‘ë‹µ ìƒì„±
        response_data = self.generate_response_with_sources(query, all_results)

        return response_data
    
# ì „ì—­ RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
rag_system = None

def get_rag_system():
    """RAG ì‹œìŠ¤í…œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global rag_system
    if rag_system is None:
        rag_system = MedicalRAGSystem()
    return rag_system